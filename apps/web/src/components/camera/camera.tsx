import React, { useRef, useEffect, useState } from 'react';
import type { CameraProps } from './types';

/**
 * ã‚«ãƒ¡ãƒ©ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨æ’®å½±æ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
 * 
 * @description
 * - ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã®èƒŒé¢ã‚«ãƒ¡ãƒ©ã‚’å„ªå…ˆã—ã¦ä½¿ç”¨
 * - æ’®å½±ã—ãŸç”»åƒã‚’base64å½¢å¼ã§è¿”å´
 * - ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®ç®¡ç†
 * 
 * @example
 * ```tsx
 * <Camera onCapture={(imageData) => console.log('æ’®å½±å®Œäº†:', imageData)} />
 * ```
 */
export const Camera: React.FC<CameraProps> = ({ onCapture }) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [isLoading, setIsLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);

  // ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–
  useEffect(() => {
    const initCamera = async () => {
      try {
        const mediaStream = await navigator.mediaDevices.getUserMedia({
          video: {
            width: { ideal: 1280 },
            height: { ideal: 720 },
            facingMode: 'environment' // èƒŒé¢ã‚«ãƒ¡ãƒ©ã‚’å„ªå…ˆ
          }
        });

        setStream(mediaStream);

        if (videoRef.current) {
          videoRef.current.srcObject = mediaStream;
        }

        setIsLoading(false);
      } catch (err) {
        console.error('ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:', err);
        setError('ã‚«ãƒ¡ãƒ©ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚«ãƒ¡ãƒ©ã®ä½¿ç”¨ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚');
        setIsLoading(false);
      }
    };

    initCamera();

    // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    return () => {
      if (videoRef.current && videoRef.current.srcObject) {
        const stream = videoRef.current.srcObject as MediaStream;
        stream.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  /**
   * æ’®å½±å‡¦ç†
   * ãƒ“ãƒ‡ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ³ãƒã‚¹ã«æç”»ã—ã€base64å½¢å¼ã§ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
   */
  const handleCapture = () => {
    if (!videoRef.current || !canvasRef.current) return;

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const context = canvas.getContext('2d');
    
    if (!context) return;

    // ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºã‚’ãƒ“ãƒ‡ã‚ªã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    // ãƒ“ãƒ‡ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ³ãƒã‚¹ã«æç”»
    context.drawImage(video, 0, 0);

    // base64å½¢å¼ã§ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    const imageData = canvas.toDataURL('image/jpeg', 0.8);
    onCapture(imageData);
  };

  if (error) {
    return (
      <div className="camera-error">
        <p>{error}</p>
      </div>
    );
  }

  return (
    <div className="camera-container">
      {isLoading && <div className="camera-loading">ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ä¸­...</div>}

      <video
        ref={videoRef}
        autoPlay
        playsInline
        muted
        className="camera-preview"
        style={{
          width: '100%',
          maxWidth: '100vw',
          height: 'auto',
          display: isLoading ? 'none' : 'block'
        }}
      />

      {/* æ’®å½±ç”¨ã®éš ã—ã‚­ãƒ£ãƒ³ãƒã‚¹ */}
      <canvas
        ref={canvasRef}
        style={{ display: 'none' }}
      />

      {!isLoading && (
        <button
          onClick={handleCapture}
          className="capture-button"
          style={{
            position: 'absolute',
            bottom: '20px',
            left: '50%',
            transform: 'translateX(-50%)',
            padding: '15px 30px',
            fontSize: '18px',
            backgroundColor: '#007bff',
            color: 'white',
            border: 'none',
            borderRadius: '50px',
            cursor: 'pointer'
          }}
        >
          ğŸ“· æ’®å½±
        </button>
      )}
    </div>
  );
}; 